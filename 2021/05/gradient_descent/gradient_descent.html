<!DOCTYPE html>
<html lang="en-us">

<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="Description" content="All about technology.">

    <!-- Enable responsiveness on mobile devices-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

    <title>
        Gradient Descent
    </title>
    
    <!-- CSS -->
    <link rel="stylesheet" href="../../../css/poole.css">
    <link rel="stylesheet" href="../../../css/syntax.css">
    <link rel="stylesheet" href="../../../css/hyde.css">
    <link href="https://fonts.googleapis.com/css?family=Crimson+Text" rel="stylesheet">

    <!-- Icons -->
    <link rel="shortcut icon" href="../../../assets/techs.png">
    <link rel="apple-touch-icon" sizes="180x180" href="../../../assets/techs.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../../assets/techs.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../../assets/techs.png">
    <!-- <link rel="manifest" href="/assets/site.webmanifest"> -->
    <link rel="mask-icon" href="../../../../assets/safari-pinned-tab.svg" color="#41a9c7">
    <link rel="shortcut icon" href="../../../assets/techs.png">
    <meta name="msapplication-TileColor" content="#00aba9">
    <meta name="msapplication-config" content="../../../assets/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">

    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS" href="../../../../atom.xml">

    <!-- Javascript -->
    
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1DEV7XD3S2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-1DEV7XD3S2');
    </script>    

</head>


<body class="theme-base-purpz">

  <div class="sidebar">
<div class="container sidebar-sticky">

  <div class="sidebar-about">
    <h1>
      <a href="../../../index.html">
        Techs Blog
      </a>
    </h1>
    <!-- <p class="lead">Simple Techs</p> -->
    <p class="lead">@arch-techs</p>

  </div>


    <nav class="sidebar-nav">
      <a class="sidebar-nav-item " href="../../../../index.html">Home</a>

      

      
      
        
        
          
        
      
        
        
          
          
        
      
        
            
        
        
          
          
        
      
        
        
          
            <a class="sidebar-nav-item " href="../../../../about/index.html">About</a>
          
        
      
        
        
          
        
      
        
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
      
        
        
          
          
        
      
        
        
          
        
      
        
        
          
        
      
        
        
          
        
      

      <div class="sidebar-nav-item">
    
        <div class="sidebar-nav-item">
          <p>
            <a href="https://github.com/hoangndst">
            Github <i class="fa fa-github" aria-hidden="true" target="_blank"></i></a>
            &nbsp;
            <a href="https://www.linkedin.com/in/nguyendinhhoang252/">
                LinkedIn <i class="fa fa-linkedin-square" target="_blank"></i>
            </a>&nbsp;
            <a href="https://www.facebook.com/techs25/" target="_blank">Facebook <i class="fa fa-facebook" aria-hidden="true"></i></a>
            &nbsp;
            <a href="https://www.instagram.com/hoangndst" target="_blank">Instagram
                <i class="fa fa-instagram" aria-hidden="true"></i></a>
        </p>
      </div>
    </nav>

    <p>&copy All rights reserved.</p>
  </div>
</div>

<!-- Mailchimp -->
<script type="text/javascript" src="https://downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script>

<script type="text/javascript">
function showMailingPopUp() {
    console.log("showing popup");
    window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us8.list-manage.com","uuid":"31c71a4d79bd53ab3c537a59e","lid":"2416515c90","uniqueMethods":true}) })
    document.cookie = "MCPopupClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
};

document.getElementById("open-popup").onclick = function() {showMailingPopUp()};
</script>


    <div class="content container">
      <div class="post">
  <h1 align="center" class="post-title">Gradient Descent</h1>
  
  <div>
      <!-- Snippet to calculate reading time assuming WPM 200 -->
<span style="display: inline" class="post-date" title="Estimated read time">
    28.05.2021 &middot; @arch-techs
</span>
  </div>
  <br>
  <p>Content:</p>

  <ul>
    <li><a href="#1-introduction">1. Giới thiệu</a>
      <ul>
        <li><a href="#11-why-gradient-descent">1.1. Tại sao chúng ta cần GA?</a></li>
        <li><a href="#12-methodology">1.2. Phương pháp</a></li>
      </ul>
    </li>
    <li><a href="#2-gradient-descent-for-linear-regression">2. Gradient Descent và Linear Regression</a>
      <ul>
        <li><a href="#21-matrix-derivatives">2.1. Đạo hàm ma trận</a></li>
        <li><a href="#22-numerical-differentiation">2.2. Vi phân số học</a></li>
        <li><a href="#23-python-code-for-visualization">2.3. Mô phỏng bằng Python</a></li>
      </ul>
    </li>
    <li><a href="#3-discussion">3. Discussion</a>
      <ul>
        <li><a href="#31-when-to-stop">3.1. When to stop?</a></li>
        <li><a href="#32-stucking-in-local-optimum">3.2. Stucking in Local Optimum</a></li>
        <li><a href="#33-speed-to-convergence-learning-rate">3.3. Speed to convergence (Learning rate)</a></li>
        <li><a href="#34-disadvantage-compared-to-using-formula">3.4. Disadvantage compared to using formula</a></li>
        <li><a href="#35-speedup-gd">3.5. Speedup GD</a></li>
      </ul>
    </li>
    <li><a href="#4-reference">4. Reference</a></li>
  </ul>
  


<p><a name="1-introduction"></a></p>
<p id="1-introduction">1. Giới thiệu</p>
<p><a name="11-why-gradient-descent"></a></p>
<p id="11-why-gradient-descent">1.1. Tại sao chúng ta cần GD?</p>

<p>
Chúng ta có thể dễ dàng tìm được hàm dự đoạn từ một tập số liệu cho trước nhờ vào công thức của hồi quy tuyến tính (Linear Regression)
\begin{equation} \tag{1}\label{eq:1}
\hat{\mathbf{x}} = (A^TA)^{-1}A^T\mathbf{b}
\end{equation}
nhưng do trong đó có một hàm $inverse$ nếu dữ liệu ít và số chiều nhỏ không sao nhưng khi làm việc với những lượng dữ liệu lớn hơn, nhiều chiều hơn thì nó sẽ tốn rất nhiều tài nguyên của máy tính. Vậy nên ta phải sử dụng đến Gradient Descent, một thuật toán cổ điển những vẫn rất phổ biến hiện nay.</p>


<p>Hay việc tìm cực trị của một hàm số, phương trình $f ′ (x) = 0$ không thể được giải một cách dễ dàng. Trong trường hợp này, chúng ta có thể sử dụng thuật toán gọi gradient descent để tìm giải pháp gần đúng.</p>
<!-- <p><a name="12-methodology"></a></p> -->
<p id="12-methodology">1.2 Phương pháp</p>
<p>Suy giảm độ dốc (còn gọi là giảm độ dốc, tiếng Anh: gradient descent) là một thuật toán tối ưu hóa lặp bậc nhất để tìm một cực trị của một hàm khả vi. Để tìm cực tiểu cục bộ của một hàm sử dụng suy giảm độ dốc, người ta có thể thực hiện các bước tỷ lệ thuận với âm của gradient (hoặc độ dốc xấp xỉ) của hàm tại điểm hiện tại. Nhưng nếu thực hiện các bước tương ứng với dương của gradient thì tiếp cận được một cực đại cục bộ của hàm số đó; phương pháp này được gọi là tăng độ dốc (gradient ascent).</p>
<p>Cụ thể hơn, GD sẽ thay đổi lặp đi lặp lại giá trị của $x \; (x := x + \beta)$ để trong mỗi lần lặp lại, hy vọng rằng $f (x)$ ngày càng nhỏ hơn và tiến gần đến mức cực tiểu.</p>
<p>Cách để điều chỉnh $\beta$ và đảm bảo $f(x)$ sẽ giảm là cho $\beta$ bằng một phần âm của gradient: $\beta = -\alpha f'(x)$, trong đó $\alpha$ là một số dương và nó được gọi là <code>learning rate</code>. Cuối cùng ta được:</p>

\begin{equation} \tag{2}\label{eq:2}
x := x - \alpha f'(x)
\end{equation}

<p>Theo như hình 1 thì tại điểm $x_{0}$ ta có $f'(x_{0}) < 0 \Rightarrow \alpha f'(x_{0}) < 0 $ có nghĩa là giá trị x sẽ tăng hay tiến về bên phải làm cho giá trị $f(x)$ giảm dần về cực tiểu.</p>

<center>
  <img src="/assets/img/hambac4.png" width="400">
  <p>Figure 1</p>
</center>

<p id="2-gradient-descent-for-linear-regression">2. Gradient Descent và Linear Regression.</p>
<p>Bây giờ chúng ta hãy đi qua khái niệm đạo hàm ma trận (để làm việc với dữ liệu nhiều chiều) và vi phân số học (để tính toán gradient gần đúng tại một giá trị cụ thể của $x$).</p>
<p id="21-matrix-derivatives">2.1 Đạo hàm ma trận</p>
<p>Trong ví dụ trước, $x$ chỉ là vectơ một chiều, nhưng thực tế các bài toán đưa ra $x$ cũng có thể là một vectơ trong không gian n chiều.</p>
<p>Trong hồi quy tuyến tính thì $x$ là một vector, công thức đạo hàm của nó là:</p>
\begin{equation}
\triangledown_x f(x) = \begin{bmatrix}
\frac{\partial f}{\partial x_{1}}\newline
 \vdots \newline
 \frac{\partial f}{\partial x_{m}} 
\end{bmatrix} 
\end{equation}
<p id="22-numerical-differentiation">2.2. Vi phân số học</p>

<p>Theo như vi phân số học chúng ta có thể tính đạo hàm theo \eqref{eq:2.3} với sai số nhỏ so với công thức bình thường \eqref{eq:2.2}.</p>

\begin{equation}\tag{2} \label{eq:2.2}
f’(x) = \lim_{\varepsilon \rightarrow 0}\frac{f(x + \varepsilon) - f(x)}{\varepsilon}
\end{equation}
\begin{equation}\tag{3} \label{eq:2.3}
f’(x) \approx \frac{f(x + \varepsilon) - f(x - \varepsilon)}{2\varepsilon} 
\end{equation}

<p>Bạn có thể đọc thêm tại đây: <a target="_blank" href="https://en.wikipedia.org/wiki/Numerical_differentiation" >Numerical Differentiation</a></p>

<p id="23-python-code-for-visualization">2.3 Mô phỏng bằng Python</p>



</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">

        

    
  </ul>
</div>

<!-- Default Statcounter code for My blog
http://hoangndst.github.io -->
<p><small>Total visits: 
<script type="text/javascript">
var sc_project=12514193; 
var sc_invisible=0; 
var sc_security="220ef100"; 
var sc_text=5; 
var scJsHost = "https://";
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12514193/0/220ef100/0/"
alt="Web Analytics"></a></div></noscript><a href="https://statcounter.com/p12514193/?guest=1"> (Powered
by Statcounter)</a></small></p>
<!-- End of Statcounter Code -->
    </div>




  </body>
  
  <script src="https://use.fontawesome.com/ba4ba69796.js"></script>


</html>
